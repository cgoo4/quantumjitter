{
  "hash": "22e295b6a6a2cc5b65979d2077fd1e37",
  "result": {
    "markdown": "---\ntitle: \"The Goldilocks Principle\"\ndate: \"2020-08-09\"\ncategories: [R, sample distribution, simulation]\ndescription: \"Simulating stock portfolio returns inspired by bowls of porridge left by three bears\"\n---\n\n\n![](feature.gif){fig-alt=\"Three bowls of porridge rest on a long table. The small bowl has no heat rising from it, whilst the largest bowl is steaming hot. The middle bowl, with a spoon wedged in it, looks just right.\"}\n\n[The Goldilocks principle](https://en.wikipedia.org/wiki/Goldilocks_principle) has its origins in a children's story about a girl who tastes the bowls of porridge left by three bears. She prefers the one that is neither too hot nor too cold, but is just right.\n\nWhen it comes to investing in stocks, how many is \"just right\"?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(conflicted)\nlibrary(tidyverse)\nconflict_prefer_all(\"dplyr\")\nlibrary(wesanderson)\nlibrary(scales)\nlibrary(truncnorm)\nlibrary(usedthese)\n\nconflict_scout()\n```\n:::\n\n\nI'll use this palette.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntheme_set(theme_bw())\n\n(cols <- wes_palette(name = \"Darjeeling2\"))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/theme-1.png){width=100%}\n:::\n:::\n\n\nSuppose the [average stock market return](https://www.investopedia.com/ask/answers/042415/what-average-annual-return-sp-500.asp) is around 10%. And you do extensive research, burning the midnight oil, poring over stock fundamentals. Or perhaps you develop a cool machine learning model. And you arrive at a list of 50 promising stocks you feel confident would, on average, deliver well-above-market returns.\n\nI'll create some randomly made up stocks with an average return close to 40%. Some will tank due to events one could not foresee; I'll allow some to lose up to 20%. Similarly, some could generate exceptional returns.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\n\nstock_data <- tibble(\n  stock = chartr(\"0123456789\", \"abcdefghij\", sample(50)),\n  return = rtruncnorm(50, a = -0.2, mean = 0.4, sd = 0.5)\n)\n\nmean(stock_data$return)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.4200244\n```\n:::\n:::\n\n\nHere's the resultant distribution I'll use to assess the impact of portfolio size. Stock markets are fairly close to a normal distribution, albeit with fatter tails due to a few extreme outcomes.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstock_data |> \n  ggplot(aes(return)) +\n  geom_histogram(fill = cols[2]) +\n  scale_x_continuous(labels = label_percent()) +\n  labs(title = \"50 Randomly-generated Stock Returns\", \n       x = \"Annual Return\", y = \"Count\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/distribution-1.png){width=100%}\n:::\n:::\n\n\nNow suppose you share 2 stocks, selected at random, with 1,000 of your social network friends (selecting a different pair of stocks for each friend). Will they all still be friends a year later? And if you repeated the same scenario with portfolio sizes of 5, 10, 20 and 50 stocks per person, would that change the outcome? Let's see.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nportfolio <- \\(x) {\n  stock_data |>\n    slice_sample(n = x, replace = TRUE) |>\n    summarise(\n      portfolio_return = mean(return),\n      portfolio_size = x\n    ) |>\n    bind_rows()\n}\n\nset.seed(456)\n\nportfolios <-\n  map(c(\n    rep(2, 1000),\n    rep(5, 1000),\n    rep(10, 1000),\n    rep(20, 1000),\n    rep(50, 1000)\n  ), portfolio) |>\n  list_rbind() |> \n  mutate(portfolio_size = factor(portfolio_size))\n\nmean_returns <- portfolios |>\n  summarise(\n    mean_return = mean(portfolio_return),\n    min_return = min(portfolio_return),\n    .by = portfolio_size\n  )\n\nportfolios |>\n  ggplot(aes(portfolio_size, portfolio_return, group = portfolio_size)) +\n  geom_violin(aes(fill = portfolio_size), show.legend = FALSE) +\n  geom_label(aes(portfolio_size, 1.5,\n    label = percent(mean_return, accuracy = 1)\n  ),\n  data = mean_returns, fill = cols[4],\n  ) +\n  geom_label(aes(portfolio_size, -0.2,\n    label = percent(min_return, accuracy = 1)\n  ),\n  data = mean_returns, fill = cols[1],\n  ) +\n  scale_y_continuous(labels = label_percent(), breaks = breaks_extended(9)) +\n  scale_fill_manual(values = cols[c(1:5)]) +\n  labs(\n    x = \"Portfolio Size\", y = \"Return\",\n    title = \"How Portfolio Size Changes Downside & Upside Risk\",\n    subtitle = \"BLUE Labels = Mean Return; BROWN Labels = Worst Return\"\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/simulate-1.png){width=100%}\n:::\n:::\n\n\nSo, for all portfolio sizes, the average return across your 1,000 friends is around 42%.\n\nBut, when the portfolio size is 2, you may be erased from a few Christmas card lists (or worse). If one of those two stocks has an extreme negative outcome, there's little else in the portfolio to dissipate the effect. As the portfolio size increases, the risk (downside and upside) dramatically reduces.\n\nBut is more always better? Well, irrespective of whether your list of promising stocks resulted from desk research or a model, there will be a varying degree of confidence in the 50. A machine learning model, for example, would assign class probabilities to each stock.\n\nSo by picking a smaller number, one can select those in which one feels most confident, or which have the highest class probability. And by picking a larger number (ideally across different sectors to further reduce risk) one can weaken the effects of a bad egg or two caused by events no research or model could foresee.\n\nSo perhaps the answer is to pick a worst-case scenario one would be prepared to accept. In the plot above, accepting a small chance of only a 12% return (still better than the historical average market return), might provide the \"just right\" portfolio. A portfolio of a manageable size, focused on your highest-confidence stocks, and with pretty good odds of the desired return.\n\n## R Toolbox\n\nSummarising below the packages and functions used in this post enables me to separately create a [toolbox visualisation](/project/box) summarising the usage of packages and functions across all posts.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nused_here()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"usedthese table table-striped\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Package </th>\n   <th style=\"text-align:left;\"> Function </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> base </td>\n   <td style=\"text-align:left;\"> c[2], chartr[1], factor[1], library[6], mean[3], min[1], rep[5], sample[1], set.seed[2] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> conflicted </td>\n   <td style=\"text-align:left;\"> conflict_prefer_all[1], conflict_scout[1] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> dplyr </td>\n   <td style=\"text-align:left;\"> bind_rows[1], mutate[1], slice_sample[1], summarise[2] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> ggplot2 </td>\n   <td style=\"text-align:left;\"> aes[5], geom_histogram[1], geom_label[2], geom_violin[1], ggplot[2], labs[2], scale_fill_manual[1], scale_x_continuous[1], scale_y_continuous[1], theme_bw[1], theme_set[1] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> purrr </td>\n   <td style=\"text-align:left;\"> list_rbind[1], map[1] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> scales </td>\n   <td style=\"text-align:left;\"> breaks_extended[1], label_percent[2], percent[2] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> tibble </td>\n   <td style=\"text-align:left;\"> tibble[1] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> truncnorm </td>\n   <td style=\"text-align:left;\"> rtruncnorm[1] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> usedthese </td>\n   <td style=\"text-align:left;\"> used_here[1] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> wesanderson </td>\n   <td style=\"text-align:left;\"> wes_palette[1] </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}