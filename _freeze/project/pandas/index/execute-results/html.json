{
  "hash": "8d517e3e4c3ac9be83b0ae7b89224382",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Reticulating Tibbles\"\ndate: \"2024-05-01\"\ncategories: [R, python, deep learning, time series]\ndescription: \"Chunks of R and slithers of Python; in the caldron boil and bake\"\n---\n\n\n![](feature.gif){fig-alt=\"A wizard holding a wand casts a 'reticulate` spell and Tibbles the cat is enveloped in smoke and reappears as a cuddly pair of pandas.\"}\n\nWhat to do when a model is available (or installable) only in Python, but you code in R?\n\nI want to try the deep-learning time-series package GluonTS on average house prices by London borough. There is an R wrapper for this, but also (at the time of writing) an [open issue installing it on Apple silicon](https://github.com/business-science/modeltime.gluonts/issues/41).\n\nSo, into the caldron boil and bake; a blended approach we will take.\n\n## Libraries (R)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(conflicted)\nlibrary(tidyverse)\nconflict_prefer_all(\"dplyr\", quiet = TRUE)\nlibrary(paletteer)\nlibrary(scales)\nlibrary(janitor)\nlibrary(trelliscope)\nlibrary(reticulate)\nlibrary(clock)\nlibrary(glue)\nlibrary(gt)\nlibrary(tictoc)\nlibrary(patchwork)\nlibrary(rvest)\nlibrary(usedthese)\n\nconflict_scout()\n```\n:::\n\n\n## Theme (R)\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntheme_set(theme_bw())\n\nn <- 5\npalette <- \"vangogh::Rest\"\n\ncols <- paletteer_d(palette, n = n)\n\ntibble(x = 1:n, y = 1) |>\n  ggplot(aes(x, y, fill = cols)) +\n  geom_col(colour = \"white\") +\n  geom_label(aes(label = cols |> str_remove(\"FF$\")), \n             size = 4, vjust = 2, fill = \"white\") +\n  annotate(\n    \"label\",\n    x = (n + 1) / 2, y = 0.5,\n    label = palette,\n    fill = \"white\",\n    alpha = 0.8,\n    size = 6\n  ) +\n  scale_fill_manual(values = as.character(cols)) +\n  theme_void() +\n  theme(legend.position = \"none\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/theme-1.png){width=100%}\n:::\n:::\n\n\n\n\n## Read & Combine (R)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nraw_df <- readRDS(\"raw_df\") # file in github repo\n\n# covid cases\ncovid_df <- tribble(\n  ~date, ~covid_cases,\n  \"2026-12-31\", 0, # optimistic assumption!\n  \"2025-12-31\", NA,\n  \"2024-12-31\", NA,\n  \"2023-12-31\", 570463,\n  \"2022-12-31\", 8665437,\n  \"2021-12-31\", 9461237,\n  \"2020-12-31\", 2327686\n) |> \n  mutate(\n    date = ymd(date), \n    covid_cases = zoo::na.approx(covid_cases)\n    )\n\n# mortgage rates\nmorgage_df <- str_c(\n  \"https://www.bankofengland.co.uk/boeapps/database/\",\n  \"fromshowcolumns.asp?Travel=NIxAZxSUx&FromSeries=1&ToSeries=50&\",\n  \"DAT=ALL&\",\n  \"FNY=Y&CSVF=TT&html.x=66&html.y=26&SeriesCodes=\", \"IUMBV42\",\n  \"&UsingCodes=Y&Filter=N&title=Quoted%20Rates&VPD=Y\"\n) |>\n  read_html() |>\n  html_element(\"#stats-table\") |>\n  html_table() |>\n  clean_names() |>\n  mutate(date = dmy(date)) |>\n  filter(month(date) == 12) |> \n  rename(morg_rate = 2) |> \n  mutate(morg_rate = morg_rate / 100) |> \n  add_row(date = ymd(\"2024-12-31\"), morg_rate = 0.0371) |> \n  add_row(date = ymd(\"2025-12-31\"), morg_rate = 0.0320) |> \n  add_row(date = ymd(\"2026-12-31\"), morg_rate = 0.0304) # poundf.co.uk/mortgage-rates\n\nlong_df <- raw_df |> \n  row_to_names(row_number = 1) |> \n  clean_names() |> \n  rename(district = na) |> \n  select(\n    district, \n    date = ncol(raw_df),\n    price = overall_average,\n    volume = total_sales\n    ) |> \n  filter(\n    district != \"Total\", \n    !is.na(district), \n    .by = district\n    ) |> \n  mutate(\n    across(c(price, volume), as.numeric),\n    date = date_build(date, 12, 31),\n    district = factor(district)\n    ) |> \n  full_join(covid_df, join_by(date)) |> \n  full_join(morgage_df, join_by(date)) |> \n  complete(district, date) |> \n  arrange(date, district) |> \n  group_by(date) |> \n  fill(covid_cases, morg_rate, .direction = \"up\") |> \n  ungroup() |> \n  drop_na(district) |> \n  arrange(district, date)\n\nlong_df |> glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 1,056\nColumns: 6\n$ district    <fct> BARKING AND DAGENHAM, BARKING AND DAGENHAM, BARKING AND DA…\n$ date        <date> 1995-12-31, 1996-12-31, 1997-12-31, 1998-12-31, 1999-12-3…\n$ price       <dbl> 50568, 51692, 56234, 63893, 69511, 84149, 94483, 118906, 1…\n$ volume      <dbl> 1504, 1906, 2449, 2515, 2698, 2829, 3230, 3473, 3513, 3498…\n$ covid_cases <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ morg_rate   <dbl> 0.0813, 0.0827, 0.0740, 0.0636, 0.0692, 0.0620, 0.0565, 0.…\n```\n\n\n:::\n\n```{.r .cell-code}\nlong_df |> count(district) |> head()\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|district             |  n|\n|:--------------------|--:|\n|BARKING AND DAGENHAM | 32|\n|BARNET               | 32|\n|BEXLEY               | 32|\n|BRENT                | 32|\n|BROMLEY              | 32|\n|CAMDEN               | 32|\n\n</div>\n:::\n:::\n\n\n## Visualise Examples (R)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlong_df |>\n  mutate(district = as.character(district)) |>\n  filter(district %in% c(\"KENSINGTON AND CHELSEA\", \"RICHMOND UPON THAMES\")) |>\n  pivot_longer(-c(date, district), names_to = \"var\") |>\n  mutate(var = fct_inorder(var)) |>\n  split(~ district + var) |>\n  imap(\n    \\(x, y) {\n      scale_y <- if (str_ends(y, \"price\")) {\n        scale_y_continuous(\n          name = \"Average\\nPrice\",\n          label = label_currency(scale_cut = cut_short_scale(), prefix = \"£\")\n        )\n      } else if (str_ends(y, \"volume\")) {\n        scale_y_continuous(\n          name = \"Sales\\nVolume\",\n          labels = label_number(scale_cut = cut_short_scale())\n          )\n      } else if (str_ends(y, \"covid_cases\")) {\n        scale_y_continuous(\n          name = \"Covid\\nCases\",\n          labels = label_number(scale_cut = cut_short_scale())\n          )\n      } else {\n        scale_y_continuous(\n          name = \"5yr\\nFixed\",\n          labels = label_percent()\n          )\n      }\n      remove_strip <- if (!str_ends(y, \"price$\")) theme(strip.text = element_blank())\n\n      x |>\n        ggplot(aes(date, value)) +\n        annotate(\"rect\",\n          xmin = ymd(\"2023-12-31\"), xmax = ymd(\"2026-12-31\"),\n          ymin = -Inf, ymax = Inf, alpha = 0.2, fill = cols[1]\n        ) +\n        geom_line() +\n        scale_y +\n        facet_wrap(~district, scales = \"free_y\") +\n        remove_strip +\n        labs(x = NULL)\n    }\n  ) |>\n  wrap_plots(\n    ncol = 2\n  ) + plot_layout(\n    heights = c(3, 1, 1, 1),\n    axes = \"collect_x\",\n    axis_titles = \"collect\"\n  ) +\n  plot_annotation(\n    title = \"Two Example London Boroughs\",\n    subtitle = \"Homes of Chelsea FC and the Fictional Richmond FC\",\n    caption = \"Sources: Land Registry, ONS & BoE\"\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/visualise examples-1.png){width=100%}\n:::\n:::\n\n\n## Install gluonTS (R)\n\n\n::: {.cell}\n\n```{.r .cell-code}\npy_install(\"gluonts\", \"r-reticulate\", pip = TRUE, ignore_installed = TRUE)\n\npy_list_packages(\"r-reticulate\")\n```\n:::\n\n\n## Model (Python)\n\nBy prefixing `long_df` with `r.`, Python can access the R object.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport pandas as pd\nimport numpy as np\nimport json\nimport torch\n\nfrom gluonts.dataset.pandas import PandasDataset\nfrom gluonts.torch import DeepAREstimator\nfrom gluonts.dataset.split import split\nfrom gluonts.evaluation import make_evaluation_predictions, Evaluator\nfrom itertools import tee\nfrom lightning.pytorch.callbacks import EarlyStopping\nfrom lightning.pytorch.loggers import CSVLogger\nfrom lightning.pytorch import seed_everything\n\nfull_ds = PandasDataset.from_long_dataframe(\n  r.long_df,\n  item_id = \"district\",\n  freq = \"Y\",\n  target = \"price\",\n  feat_dynamic_real = [\"covid_cases\", \"morg_rate\"],\n  past_feat_dynamic_real = [\"volume\"],\n  future_length = 3,\n  timestamp = \"date\")\n  \ntest_ds, _ = split(full_ds, offset = -1)\nval_ds, _ = split(full_ds, offset = -2)\ntrain_ds, _ = split(full_ds, offset = -3)\n  \nseed_everything(20, workers = True)\n```\n\n```{.python .cell-code}\nnp.random.seed(123)\ntorch.manual_seed(123)\n```\n\n```{.python .cell-code}\n\nearly_stop_callback = EarlyStopping(\"val_loss\", min_delta = 1e-4, patience = 5)\nlogger = CSVLogger(\".\")\n\nestimator = DeepAREstimator(\n  freq = \"Y\", \n  hidden_size = 100,\n  prediction_length = 1, \n  num_layers = 2,\n  lr = 0.01,\n  batch_size = 128,\n  num_batches_per_epoch = 100,\n  trainer_kwargs = {\n    \"max_epochs\": 50,\n    \"deterministic\": True,\n    \"enable_progress_bar\": False,\n    \"enable_model_summary\": False,\n    \"logger\": logger,\n    \"callbacks\": [early_stop_callback]\n    },\n  nonnegative_pred_samples = True)\n  \ntest_predictor = estimator.train(train_ds, val_ds)\n```\n:::\n\n\n## Learning Curve (R)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nversion <- list.files(\"lightning_logs\") |> parse_number() |> max()\n\nlog_df <- read_csv(str_c(\"lightning_logs/version_\", version, \"/metrics.csv\"),\n  show_col_types = FALSE\n)\n\nlog_df |>\n  select(-step) |>\n  mutate(\n    best_val = if_else(val_loss == min(val_loss, na.rm = TRUE), val_loss, NA),\n    best_epoch = if_else(!is.na(best_val), glue(\"Best Epoch\\n{epoch}\"), NA)\n  ) |>\n  pivot_longer(ends_with(\"_loss\"), values_drop_na = TRUE) |>\n  mutate(name = case_match(\n    name,\n    \"train_loss\" ~ \"Training\",\n    \"val_loss\" ~ \"Validation\",\n  )) |>\n  ggplot(aes(epoch, value, colour = name)) +\n  geom_line() +\n  geom_point(aes(y = best_val), show.legend = FALSE) +\n  geom_label(\n    aes(label = best_epoch),\n    size = 2,\n    nudge_y = 0.2,\n    show.legend = FALSE\n  ) +\n  labs(\n    title = \"GluonTS Learning Curve\",\n    subtitle = glue(\"Lightning Log Version {version}\"),\n    x = \"Epoch\",\n    y = \"Loss\",\n    colour = NULL\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/training curve-1.png){width=100%}\n:::\n:::\n\n\n## Test (Python)\n\n\n::: {.cell}\n\n```{.python .cell-code}\ntest_fcast = list(test_predictor.predict(test_ds))\n\nseed_everything(42, workers = True)\n```\n\n```{.python .cell-code}\nnp.random.seed(123)\ntorch.manual_seed(123)\n```\n\n```{.python .cell-code}\n# Train and predict\nforecast_it, ts_it = make_evaluation_predictions(\n    dataset = train_ds, \n    predictor = test_predictor,\n    num_samples = 1000\n)\n\n# Copy iterators\nts_it, targets = tee(ts_it) \nforecast_it, predictions = tee(forecast_it) \n\n# Calculate metrics\nevaluator = Evaluator(quantiles=[0.05, 0.5, 0.95])\nagg_metrics, item_metrics = evaluator(\n    ts_it, \n    forecast_it, \n    num_series = len(test_ds)\n)\n```\n:::\n\n\n## Metrics (R)\n\nBy prefixing `agg_metrics` with `py$`, R can access the Python object.\n\n\n::: {.cell}\n\n```{.r .cell-code}\naggregated <- as.numeric(py$agg_metrics[\"MAPE\"])\n\ncol <- compose(as.character, \\(x) cols[x])\n\npy$item_metrics |> \n  select(item_id, MAPE) |> \n  mutate(item_id = fct_reorder(item_id, MAPE)) |> \n  ggplot(aes(MAPE, item_id)) +\n  geom_vline(xintercept = aggregated, linetype = \"dashed\", colour = col(2)) +\n  geom_point() +\n  scale_x_log10() +\n  labs(\n    title = \"Test Metric by Borough\", \n    subtitle = glue(\"Overall MAPE {round(aggregated, 3)}\"), \n    x = \"MAPE (log10 scale)\", y = NULL\n    )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/metrics-1.png){width=100%}\n:::\n:::\n\n\n## Final Model (Python)\n\n\n::: {.cell}\n\n```{.python .cell-code}\nestimator = DeepAREstimator(\n  freq = \"Y\", \n  hidden_size = 100,\n  prediction_length = 3, \n  num_layers = 2,\n  lr = 0.01,\n  batch_size = 128,\n  num_batches_per_epoch = 100,\n  trainer_kwargs = {\n    \"max_epochs\": 12,\n    \"deterministic\": True,\n    \"enable_progress_bar\": False,\n    \"enable_model_summary\": False,\n    },\n  nonnegative_pred_samples = True)\n\nseed_everything(42, workers = True)\n```\n\n```{.python .cell-code}\nnp.random.seed(123)\ntorch.manual_seed(123)\n```\n\n```{.python .cell-code}\n\nfinal_predictor = estimator.train(full_ds)\n\nfuture_fcast = list(final_predictor.predict(full_ds))\n```\n:::\n\n\n## Forecast (R)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfc_ls = c(py$test_fcast, py$future_fcast)\n\nyears_df <- fc_ls |>\n  map(\"mean_ts\") |>\n  map(as.data.frame.table) |>\n  list_rbind() |>\n  mutate(\n    date = Var1,\n    fcast = Freq,\n    .keep = \"unused\"\n  )\n\nquantiles_df <- map(1:length(fc_ls), \\(x) {\n  fc_ls[[x]]$`_sorted_samples` |>\n    as_tibble() |>\n    reframe(\n      across(everything(), \\(x) quantile(x, probs = c(0.05, 0.1, 0.5, 0.9, 0.95))),\n      quantile = c(\"pi90_low\", \"pi80_low\", \"median\", \"pi80_high\", \"pi90_high\")\n    ) |>\n    pivot_longer(-quantile, names_to = \"window\") |>\n    mutate(sample = x, district = fc_ls[[x]]$item_id)\n}, .progress = TRUE) |>\n  list_rbind() |>\n  pivot_wider(names_from = quantile, values_from = value) |>\n  bind_cols(years_df) |>\n  pivot_longer(starts_with(\"pi\"), names_to = c(\"pi\", \".value\"), names_pattern = \"(.*)_(.*)\") |>\n  nest(.by = c(district, sample)) |>\n  mutate(sample = row_number(), .by = district) |>\n  unnest(data) |>\n  mutate(pi_sample = str_c(`pi`, \"-\", sample) |> factor()) |>\n  arrange(district, date, sample) |>\n  mutate(date = str_c(date, \"-12\", \"-31\") |> ymd())\n\ndistricts <- long_df |> summarise(n_distinct(district)) |> pull()\n```\n:::\n\n\n## Trelliscope (R)\n\n\n::: {.cell scale='0.5'}\n\n```{.r .cell-code}\npanels_df <- long_df |>\n  left_join(quantiles_df, join_by(district, date)) |> \n  ggplot(aes(date, price)) +\n  geom_line() +\n  geom_ribbon(aes(y = median, ymin = low, ymax = high, fill = fct_rev(pi_sample)),\n    alpha = 1, linewidth = 0) +\n  geom_line(aes(date, median), colour = \"white\") +\n  scale_fill_manual(values = col(c(1, 1, 5, 5))) +\n  scale_y_continuous(labels = label_currency(scale_cut = cut_short_scale(), prefix = \"£\")) +\n  facet_panels(vars(district), scales = \"free_y\") +\n  labs(\n    title = glue(\"Price Forecasts for {districts} Postal Districts\"), \n    subtitle = \"Backtest & Future Forecasts with 80 & 90% Prediction Intervals\",\n    caption = \"DeepAR: Probabilistic Forecasting with Autoregressive Recurrent Networks\",\n    x = NULL, y = \"Avg Price\", fill = \"Prediction\\nInterval\"\n    ) +\n  theme(legend.position = \"none\")\n\nslope <- \\(x, y) coef(lm(y ~ x))[2]\n\nsummary_df <- long_df |> \n  summarise(\n    last_price = nth(price, -4), \n    slope = slope(date, price),\n    .by = district)\n\npanels_df |>\n  as_panels_df(as_plotly = TRUE) |>\n  as_trelliscope_df(\n    name = \"Average London House Prices\",\n    description = str_c(\n      \"Time series of house prices by London post code district \",\n      \"sourced from HM Land Registry Open Data.\"\n    )\n  ) |>\n  left_join(summary_df, join_by(district)) |>\n  set_default_labels(c(\"district\", \"last_price\")) |>\n  set_var_labels(\n    district = \"Post Code District\",\n    last_price = \"Last Year's Avg Price\"\n  ) |>\n  set_default_sort(c(\"last_price\"), dirs = \"desc\") |>\n  set_tags(\n    stats = c(\"last_price\", \"slope\"),\n    info = \"district\"\n  ) |>\n  set_theme(\n    primary = col(1),\n    dark = col(1),\n    light = col(5),\n    light_text_on_dark = TRUE,\n    dark_text = col(1),\n    light_text = col(5),\n    header_background = col(1),\n    header_text = NULL\n  ) |>\n  view_trelliscope()\n```\n\n  <div style=\"width: 100%; height: 500px; padding-bottom: 5px;\"><iframe\n      style=\"\n        transform: scale(0.5);\n        width: 200%;\n        height: 1000px;\n        margin: 0;\n        padding: 0;\n        border: 1px solid #efefef;\n        transform-origin: top left;\n      \"\n      src=\"index_files/figure-html//fc trelliscope/index.html\"\n      title=\"Average London House Prices\"\n      width=\"200%px\"\n      height=\"1000pxpx\"\n      allowfullscreen\n      style=\"margin: 0; padding: 0; border: 1px solid #efefef;\"\n    >\n    </iframe></div>\n:::\n\n\n## R Toolbox\n\nSummarising below the packages and functions used in this post enables me to separately create a [toolbox visualisation](/project/box) summarising the usage of packages and functions across all posts.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nused_here()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"usedthese table table-striped\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Package </th>\n   <th style=\"text-align:left;\"> Function </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> base </td>\n   <td style=\"text-align:left;\"> as.character[2], as.numeric[1], c[14], col[8], factor[2], if[4], is.na[2], length[1], library[14], list[2], list.files[1], max[1], min[1], ncol[1], readRDS[1], round[1], saveRDS[1], split[4] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> clock </td>\n   <td style=\"text-align:left;\"> date_build[1] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> conflicted </td>\n   <td style=\"text-align:left;\"> conflict_prefer_all[1], conflict_scout[1] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> dplyr </td>\n   <td style=\"text-align:left;\"> across[2], arrange[3], bind_cols[1], case_match[1], count[1], filter[3], full_join[2], group_by[1], if_else[2], join_by[4], left_join[2], mutate[15], n_distinct[1], nth[1], pull[1], reframe[1], rename[2], row_number[1], select[3], summarise[2], ungroup[1], vars[1] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> forcats </td>\n   <td style=\"text-align:left;\"> fct_inorder[1], fct_reorder[1], fct_rev[1] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> ggplot2 </td>\n   <td style=\"text-align:left;\"> aes[10], annotate[2], element_blank[1], facet_wrap[1], geom_col[1], geom_label[2], geom_line[4], geom_point[2], geom_ribbon[1], geom_vline[1], ggplot[5], labs[4], scale_fill_manual[2], scale_x_log10[1], scale_y_continuous[5], theme[3], theme_bw[1], theme_set[1], theme_void[1] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> glue </td>\n   <td style=\"text-align:left;\"> glue[4] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> janitor </td>\n   <td style=\"text-align:left;\"> clean_names[2], row_to_names[1] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> lubridate </td>\n   <td style=\"text-align:left;\"> dmy[1], month[1], ymd[7] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> paletteer </td>\n   <td style=\"text-align:left;\"> paletteer_d[1] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> patchwork </td>\n   <td style=\"text-align:left;\"> plot_annotation[1], plot_layout[1], wrap_plots[1] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> pillar </td>\n   <td style=\"text-align:left;\"> glimpse[1] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> purrr </td>\n   <td style=\"text-align:left;\"> compose[1], imap[1], list_rbind[3], map[4] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> readr </td>\n   <td style=\"text-align:left;\"> parse_number[1], read_csv[2] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> reticulate </td>\n   <td style=\"text-align:left;\"> py_install[1], py_list_packages[1] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> rvest </td>\n   <td style=\"text-align:left;\"> html_element[1], html_table[1] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> scales </td>\n   <td style=\"text-align:left;\"> cut_short_scale[4], label_currency[2], label_number[2], label_percent[1] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> stats </td>\n   <td style=\"text-align:left;\"> coef[1], lm[1], quantile[1] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> stringr </td>\n   <td style=\"text-align:left;\"> str_c[7], str_ends[4], str_remove[1] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> tibble </td>\n   <td style=\"text-align:left;\"> add_row[3], as_tibble[1], tibble[1], tribble[1] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> tictoc </td>\n   <td style=\"text-align:left;\"> tic[1], toc[1] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> tidyr </td>\n   <td style=\"text-align:left;\"> complete[1], drop_na[1], fill[1], nest[1], pivot_longer[4], pivot_wider[1], unnest[1] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> tidyselect </td>\n   <td style=\"text-align:left;\"> ends_with[1], everything[1], starts_with[1] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> trelliscope </td>\n   <td style=\"text-align:left;\"> as_panels_df[1], as_trelliscope_df[1], facet_panels[1], set_default_labels[1], set_default_sort[1], set_tags[1], set_theme[1], set_var_labels[1], view_trelliscope[1] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> usedthese </td>\n   <td style=\"text-align:left;\"> used_here[1] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> utils </td>\n   <td style=\"text-align:left;\"> head[1] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> xml2 </td>\n   <td style=\"text-align:left;\"> read_html[1] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> zoo </td>\n   <td style=\"text-align:left;\"> na.approx[1] </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}